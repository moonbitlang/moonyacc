// Copyright (C) 2025 International Digital Economy Academy
//
// This program is free software; you can redistribute it and/or
// modify it under the terms of the GNU General Public License
// as published by the Free Software Foundation; version 2.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program; if not, see <https://www.gnu.org/licenses/>.

///|
pub(all) enum Mode {
  Default
  JsonCst(token_payload_rewrite~ : TokenPayloadRewrite?)
  OnlyTokens
}

///|
pub(all) enum TokenPayloadRewrite {
  NoPayload
  JsonPayload
}

///|
pub(all) enum InputMode {
  Array
  Pull
}

///|
pub fn compile(
  parser_spec_str : String,
  mode~ : Mode = Default,
  input_mode~ : InputMode = Array,
  filename~ : String,
  external_tokens~ : Bool = false,
  no_comments~ : Bool = false,
  source_map_builder? : &@codegen.SourceMapBuilder,
  generator~ : &@codegen.CodeGenerator
) -> String {
  let lexer = @parser.new_lexer(parser_spec_str)
  fn token() {
    lexer.next_token?().unwrap()
  }

  let spec = try {
    @parser.spec!(token, 0)
  } catch {
    @parser.UnexpectedToken(token, loc, expected) => {
      let loc_str = loc_to_string(filename, parser_spec_str, loc)
      let expected_str = array_to_or_list(expected.map(Show::to_string)[:])
      println_to_stderr(
        "SyntaxError: Unexpected token \{token.kind()}, expected \{expected_str}.\n  at \{loc_str}",
      )
      exit(1)
    }
  }
  let spec = @elab.elaborate(
    spec,
    json_cst=match mode {
      JsonCst(token_payload_rewrite=None) => Yes(None)
      JsonCst(token_payload_rewrite=Some(NoPayload)) => Yes(Some(NoPayload))
      JsonCst(token_payload_rewrite=Some(JsonPayload)) => Yes(Some(JsonPayload))
      Default | OnlyTokens => No
    },
  )
  let spec = @inline.eliminate_inline(spec)
  let terminals = []
  let nonterminals = []
  let terminal_by_name : Map[String, @grm.Terminal] = {}
  let nonterminal_by_name : Map[String, @grm.Nonterminal] = {}
  for token in spec.tokens {
    let terminal : @grm.Terminal = {
      name: token.name,
      num: terminals.length(),
      prec: match token.prec {
        None => None
        Some((prec, NonAssoc)) => Some((prec, @grm.NonAssoc))
        Some((prec, LeftAssoc)) => Some((prec, @grm.LeftAssoc))
        Some((prec, RightAssoc)) => Some((prec, @grm.RightAssoc))
      },
    }
    terminal_by_name[token.name] = terminal
    terminals.push(terminal)
  }
  for rule in spec.rules {
    let nonterminal : @grm.Nonterminal = {
      name: rule.name,
      num: nonterminals.length(),
      productions: [],
    }
    nonterminal_by_name[rule.name] = nonterminal
    nonterminals.push(nonterminal)
  }
  fn get_terminal_by_name(name : String) -> @grm.Terminal {
    terminal_by_name.get(name).unwrap()
  }

  fn get_nonterminal_by_name(name : String) -> @grm.Nonterminal {
    nonterminal_by_name.get(name).unwrap()
  }

  let production_meta_map : Map[Int, @codegen.ProductionMeta] = {}
  let terminal_meta_map : Map[Int, @codegen.TerminalMeta] = {}
  let nonterminal_meta_map : Map[Int, @codegen.NonTerminalMeta] = {}
  let productions = []
  let starts : Array[String] = spec.start_rules.map(fn(rule) { rule.name })
  let position_data_type = spec.position_type.or(
    Constr(pkg=None, generator.void_type(), []),
  )
  let derive_map = spec.derive_map
  for token in spec.tokens {
    let terminal = get_terminal_by_name(token.name)
    terminal_meta_map[terminal.num] = {
      data_type: token.type_,
      image: token.image,
    }
  }
  match mode {
    OnlyTokens => {
      let output = StringBuilder::new()
      generator.codegen_tokens(
        terminals,
        fn(name) {
          terminal_meta_map.get_or_init(get_terminal_by_name(name).num, fn() {
            { data_type: None, image: None }
          })
        },
        output,
        no_comments~,
        derive_map=spec.derive_map,
      )
      return output.to_string()
    }
    _ => ()
  }
  for rule in spec.rules {
    let lhs = get_nonterminal_by_name(rule.name)
    match rule.type_ {
      Some(type_) => nonterminal_meta_map[lhs.num] = { data_type: type_ }
      None =>
        match nonterminal_meta_map[lhs.num] {
          Some(_) => ()
          None =>
            nonterminal_meta_map[lhs.num] = {
              data_type: Constr(pkg=None, generator.void_type(), []),
            }
        }
    }
    for clause in rule.clauses {
      let production_num = productions.length()
      let production : @grm.Production = {
        num: production_num,
        lhs,
        rhs: clause.items.map(fn(item) {
          match item.term {
            Token(token) => T(get_terminal_by_name(token.name))
            RuleCall(rule, []) => NT(get_nonterminal_by_name(rule.name))
            RuleCall(_, _) => panic()
          }
        }),
        prec: clause.prec,
      }
      productions.push(production)
      lhs.productions.push(production)
      production_meta_map[production_num] = { action: clause.action }
    }
  }
  let starts = starts.map(fn(name) {
    let start_nt = get_nonterminal_by_name(name)
    let augmented_start_nt : @grm.Nonterminal = {
      num: nonterminals.length(),
      name: "\{name}_prime",
      productions: [],
    }
    nonterminal_by_name[augmented_start_nt.name] = augmented_start_nt
    nonterminals.push(augmented_start_nt)
    nonterminal_meta_map[augmented_start_nt.num] = nonterminal_meta_map[start_nt.num].unwrap()
    let production : @grm.Production = {
      num: productions.length(),
      lhs: augmented_start_nt,
      rhs: [NT(start_nt)],
      prec: None,
    }
    productions.push(production)
    augmented_start_nt.productions.push(production)
    production
  })
  let grammar : @grm.Grammar = { terminals, nonterminals, productions, starts }
  let automaton = @lr1.Automaton::build(grammar)
  let errors = @lr1.resolve_conflicts(automaton.conflicts)
  for error in errors {
    // TODO: detailed error message
    match error {
      Reduce_conflict_resolved_by_presentation_order(_) =>
        println_to_stderr("Reduce conflict resolved by presentation order")
      Shift_reduce_conflict_resolved_without_precedence(_) =>
        println_to_stderr("Shift-reduce conflict resolved without precedence")
      Shift_reduce_conflict_not_resolved_because_of_non_assoc(_) =>
        println_to_stderr(
          "Shift-reduce conflict not resolved because of non-associativity",
        )
    }
  }
  let meta : @codegen.MetaProvider = {
    header: spec.header.or_default(),
    footer: spec.trailer.or_default(),
    position_data_type,
    terminal_meta: fn(name) {
      terminal_meta_map.get_or_init(get_terminal_by_name(name).num, fn() {
        { data_type: None, image: None }
      })
    },
    nonterminal_meta: fn(name) {
      nonterminal_meta_map[get_nonterminal_by_name(name).num].unwrap()
    },
    production_meta: fn(num) { production_meta_map[num].unwrap() },
    derive_map,
  }
  let output_buffer = StringBuilder::new()
  let output = @logger_with_cursor.new(output_buffer)
  generator.codegen(
    grammar,
    automaton,
    meta,
    output,
    source_map_builder~,
    grammar_filename=@_driver_util.path_basename(filename),
    mode=match mode {
      OnlyTokens => panic()
      Default => Default
      JsonCst(token_payload_rewrite=None) => JsonCst(token_payload_rewrite=None)
      JsonCst(token_payload_rewrite=Some(NoPayload)) =>
        JsonCst(token_payload_rewrite=Some(NoPayload))
      JsonCst(token_payload_rewrite=Some(JsonPayload)) =>
        JsonCst(token_payload_rewrite=Some(JsonPayload))
    },
    input_mode=match input_mode {
      Array => Array
      Pull => Pull
    },
    external_tokens~,
    no_comments~,
  )
  output_buffer.to_string()
}
